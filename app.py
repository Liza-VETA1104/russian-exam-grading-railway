{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274af6da-69fa-43e5-9532-43d60e9a784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "# === Загрузка моделей ===\n",
    "tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "model_q1 = joblib.load('model_q1.pkl')\n",
    "model_q2 = joblib.load('model_q2.pkl')\n",
    "model_q3 = joblib.load('model_q3.pkl')\n",
    "\n",
    "# Новая модель для вопроса 4\n",
    "model_q4 = joblib.load('model_q4_enhanced.pkl')\n",
    "tfidf_q4 = joblib.load('tfidf_q4.pkl')\n",
    "scaler_q4 = joblib.load('scaler_q4.pkl')\n",
    "\n",
    "# === Функции обработки ===\n",
    "def clean_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, ' ', str(text)).replace('  ', ' ').strip()\n",
    "\n",
    "def remove_instruction(transcript, q_num):\n",
    "    if q_num == 1: start_phrase = \"Начинайте свой диалог.\"\n",
    "    elif q_num == 2: start_phrase = \"Ответьте на вопросы собеседника полными предложениями.\"\n",
    "    elif q_num == 3: start_phrase = \"Поблагодарите за предоставленную информацию.\"\n",
    "    elif q_num == 4: start_phrase = \"Когда будете готовы, можете начинать описывать.\"\n",
    "    else: return transcript\n",
    "    idx = transcript.find(start_phrase)\n",
    "    return transcript[idx + len(start_phrase):].strip() if idx != -1 else transcript\n",
    "\n",
    "def extract_features(text):\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    n_sents = len([s for s in sentences if len(s.strip()) > 0])\n",
    "    words = text.split()\n",
    "    n_words = len(words)\n",
    "    avg_sent_len = n_words / n_sents if n_sents > 0 else 0\n",
    "    return [n_sents, n_words, avg_sent_len, int('?' in text)]\n",
    "\n",
    "def get_q4_features_enhanced(text):\n",
    "    text_low = text.lower()\n",
    "    return {\n",
    "        'has_season': int(any(w in text_low for w in ['лето', 'зима', 'весна', 'осень', 'тёплое время', 'снег', 'дождь'])),\n",
    "        'has_place': int(any(w in text_low for w in ['кухня', 'дом', 'парк', 'вокзал', 'река', 'улица'])),\n",
    "        'has_people_count': int(any(w in text_low for w in ['один', 'два', 'три', 'четыре', 'много детей', 'целая семья'])),\n",
    "        'has_family': int(any(w in text_low for w in ['в нашей семье', 'у меня трое детей', 'я старшая', 'мой брат'])),\n",
    "        'has_hobby': int(any(w in text_low for w in ['люблю готовить', 'играю в футбол', 'гуляю на природе', 'вышиваю'])),\n",
    "        'n_sentences': len(re.split(r'[.!?]+', text)),\n",
    "        'is_structured': int(len(re.findall(r'\\b(на картинке|изображено|я вижу|расскажу о)\\b', text_low)) >= 1),\n",
    "        'has_emotion': int(any(w in text_low for w in ['радостный', 'счастлив', 'улыбается', 'весело'])),\n",
    "        'is_garbage': int(any(w in text_low for w in [\n",
    "            'characterization', 'leather.ru', 'Feit', 'Паспортный канал', 'understanding'\n",
    "        ]) or len(text.split()) < 3)\n",
    "    }\n",
    "\n",
    "# === Основная функция ===\n",
    "def grade_exam(file):\n",
    "    # Поддержка разных версий Gradio\n",
    "    if file is None:\n",
    "        raise ValueError(\"Пожалуйста, загрузите CSV-файл\")\n",
    "    file_path = file if isinstance(file, str) else file.name\n",
    "    \n",
    "    df = pd.read_csv(file_path, sep=';', on_bad_lines='skip')\n",
    "\n",
    "    if 'Оценка экзаменатора' in df.columns:\n",
    "        df = df.drop(columns=['Оценка экзаменатора'])\n",
    "\n",
    "    required_cols = ['Id экзамена', 'Id вопроса', '№ вопроса', 'Текст вопроса',\n",
    "                     'Картинка из вопроса', 'Транскрибация ответа', 'Ссылка на оригинальный файл запис']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Отсутствует колонка: {col}\")\n",
    "\n",
    "    df['Текст вопроса_clean'] = df['Текст вопроса'].apply(clean_html)\n",
    "    df['cleaned_transcript'] = df.apply(\n",
    "        lambda row: remove_instruction(row['Транскрибация ответа'], row['№ вопроса']),\n",
    "        axis=1\n",
    "    )\n",
    "    df['combined_text'] = df['Текст вопроса_clean'] + ' [SEP] ' + df['cleaned_transcript'].fillna('')\n",
    "\n",
    "    y_pred = np.zeros(len(df), dtype=int)\n",
    "\n",
    "    for q_num in [1, 2, 3, 4]:\n",
    "        mask = df['№ вопроса'] == q_num\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        if q_num == 4:\n",
    "            X_text = tfidf_q4.transform(df.loc[mask, 'combined_text'])\n",
    "            ling_feat = np.array([extract_features(txt) for txt in df.loc[mask, 'cleaned_transcript'].fillna('')])\n",
    "            ling_scaled = scaler_q4.transform(ling_feat)\n",
    "            feats = df.loc[mask, 'cleaned_transcript'].apply(get_q4_features_enhanced)\n",
    "            feature_cols = list(feats.iloc[0].keys())\n",
    "            checklist_feat = np.array([list(f.values()) for f in feats])\n",
    "            X = hstack([X_text, csr_matrix(ling_scaled), csr_matrix(checklist_feat)])\n",
    "            pred_raw = model_q4.predict(X)\n",
    "            pred_rounded = np.array([int(np.clip(round(p), 0, 2)) for p in pred_raw])\n",
    "            pred_rounded[checklist_feat[:, -1] == 1] = 0\n",
    "            y_pred[mask] = pred_rounded\n",
    "        else:\n",
    "            X_text = tfidf.transform(df.loc[mask, 'combined_text'])\n",
    "            ling_feat = np.array([extract_features(txt) for txt in df.loc[mask, 'cleaned_transcript'].fillna('')])\n",
    "            ling_scaled = scaler.transform(ling_feat)\n",
    "            q_norm = np.full((mask.sum(), 1), q_num / 4.0)\n",
    "            X = hstack([X_text, csr_matrix(q_norm), csr_matrix(ling_scaled)])\n",
    "            model = {1: model_q1, 2: model_q2, 3: model_q3}[q_num]\n",
    "            pred_raw = model.predict(X)\n",
    "            if q_num in (1, 3):\n",
    "                pred_rounded = np.array([0 if p < 0.5 else 1 for p in pred_raw])\n",
    "            else:\n",
    "                pred_rounded = np.array([int(np.clip(round(p), 0, 2)) for p in pred_raw])\n",
    "            y_pred[mask] = pred_rounded\n",
    "\n",
    "    df['Оценка экзаменатора'] = y_pred\n",
    "    output_cols = ['Id экзамена', 'Id вопроса', '№ вопроса', 'Текст вопроса',\n",
    "                   'Картинка из вопроса', 'Оценка экзаменатора',\n",
    "                   'Транскрибация ответа', 'Ссылка на оригинальный файл запис']\n",
    "    df = df[output_cols]\n",
    "\n",
    "    output_path = '/tmp/graded_output.csv'\n",
    "    df.to_csv(output_path, index=False, sep=';')\n",
    "    return output_path\n",
    "\n",
    "# === Запуск ===\n",
    "iface = gr.Interface(\n",
    "    fn=grade_exam,\n",
    "    inputs=gr.File(label=\"Загрузите CSV с экзаменационными данными\"),\n",
    "    outputs=gr.File(label=\"Скачать результат с оценками\"),\n",
    "    title=\"Автоматическая оценка устного экзамена по русскому языку (v2)\",\n",
    "    description=\"MAE = 0.0397 • Загрузите файл в формате CSV с разделителем ';'\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(server_name=\"0.0.0.0\", ssr_mode=False, quiet=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
